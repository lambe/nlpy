Matrix-Free Augmented Lagrangian TODO List
------------------------------------------

- Absolute and relative convergence tolerances at each level of method

- Counters for calls to original NLP objective, constraint, gradient, and 
jprod and jtprod functions
	- done locally for MFModel May 17, 2012; already in MFAmplModel

- Nocedal-Yuan backtracking
	- implemented, May 15, 2012

- Magical steps for slack variables
	- implemented, May 16, 2012
	- initialization of slack variables with magical steps added June 5, 2012

- Nonmonotone update strategy
    - implemented, May 31, 2012

- Automatic variable / constraint scaling

- Store previous x to prevent repeated function evaluations at the same point
	- early version complete May 16, 2012, more advanced work in progress, see below

- Detect infeasible problems reliably (use Lancelot A strategy?)
	- simple implementation added May 16, 2012


More "radical" / experimental ideas:

- "Smart" selection of initial TR radius for each major iteration

- Use SHA1 key for storing x (see above) for performance
	- implemented May 17, 2012

- "Smart" selection of initial penalty parameter

- "Smart" selection of initial multipliers, e.g. least-squares initialization
	- added option for LSQR to compute multipliers June 4, 2012

- Extrapolation of x near a solution with good multiplier estimates

- More interesting ways of computing the step???

- Interface with full CUTEr test set???
